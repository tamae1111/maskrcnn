{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c8af41-bdd2-4d9c-a5e4-a1a069e4f817",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcustombdd\u001b[0m/                                \u001b[01;34mmodules\u001b[0m/\n",
      "Faster_R_CNN_ver_sagemaker_moduled.ipynb  requirements.txt\n",
      "\u001b[01;34mmodels\u001b[0m/                                   sagemaker_entry_point.py\n",
      "model.tar.gz                              testInf.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/fasterRcnn/colab_frcnn'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのテストと、sagemakerのデプロイを行うファイル\n",
    "%ls\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96dfd3e2-96b9-4f43-afef-da8a94ab5382",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  6 08:08:26 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   47C    P8    15W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fccc2ac3-e445-42e5-bd01-9f1f4472cf40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from modules.infer import testShowInferenceImage\n",
    "from modules.train import train\n",
    "from modules.MLparamaters import getMLParamaters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2fd83c6-f49a-45a5-8b2a-26e678e4d9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(torch.__version__)\n",
    "# print(torchvision.__version__)\n",
    "# print(torchtext.__version__)\n",
    "# print(torchaudio.__version__)\n",
    "# 1.13.1\n",
    "# 0.14.1\n",
    "# 0.14.1\n",
    "# 0.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc3b38-4726-482d-82fa-0386dcde2ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "! echo checkpoint1\n",
    "\n",
    "# ここ、pip installは初回のみでいいかも\n",
    "!pip install -r requirements.txt\n",
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8fc07-bf7e-4194-bc7d-ce643cac98a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "#学習済みモデルで推論する場合\n",
    "paramaters = getMLParamaters()\n",
    "\n",
    "# train()\n",
    "\n",
    "use_model=torch.load(paramaters.path+'/models/model.pt')\n",
    "\n",
    "testShowInferenceImage(use_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365ced02-f747-4430-8c01-cfda67e9ad6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/model.pt\n"
     ]
    }
   ],
   "source": [
    "# !tar zcvf model.tar.gz models/model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8eccb9-a824-490b-8cb2-5b9b9a6e0301",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::958305726855:role/service-role/AmazonSageMaker-ExecutionRole-20230406T155831\n"
     ]
    }
   ],
   "source": [
    "# sagamakerでエンドポイントデプロイ関連\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sagemaker.__version__\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "\n",
    "\n",
    "s3_path=\"s3://mlearning-bucket/sageMakerDeployTest/model/model.tar.gz\"\n",
    "\n",
    "hyper_param = {\n",
    "    'epochs':100,\n",
    "    'batch-size': 100,\n",
    "    'lr': 0.01,\n",
    "    'momentum': 0.9,\n",
    "}\n",
    "\n",
    "pytorch_model = PyTorch(model_data=s3_path,\n",
    "                            entry_point=\"sagemaker_entry_point.py\",\n",
    "                            hyperparameters=hyper_param,\n",
    "                            role=role,\n",
    "                            framework_version='1.2.0',\n",
    "                            py_version='py3',\n",
    "                            train_instance_count=2,\n",
    "                            train_instance_type='ml.c5.xlarge')\n",
    "deploy_params = {\n",
    "    'instance_type'          : 'ml.t2.medium',\n",
    "    'initial_instance_count' : 1\n",
    "}\n",
    "\n",
    "# デプロイ\n",
    "predictor = pytorch_model.deploy(**deploy_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009865e8-913a-418d-b303-0ca436b888f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# デプロイしたものの画像表示テスト\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "filename = 'testInf.jpg'\n",
    "\n",
    "# インライン表示\n",
    "%matplotlib inline\n",
    "\n",
    "# Read image into memory\n",
    "payload = None\n",
    "with open(filename, 'rb') as f:\n",
    "    payload = f.read()\n",
    "\n",
    "#画像の表示\n",
    "frombuff = np.frombuffer(payload, dtype='uint8') # byteをnumpyにしている(1次元)\n",
    "\n",
    "input_data = cv2.imdecode(frombuff, cv2.IMREAD_UNCHANGED) # numpyを画像の形式にdecodeしている。\n",
    "\n",
    "bytearray_data = bytearray(payload)\n",
    "plt.imshow(input_data) \n",
    "plt.show()\n",
    "\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = IdentitySerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "results = predictor.predict(bytearray_data, initial_args={'ContentType': 'application/x-image'})\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f33771-94da-40eb-be06-06b751d7bb9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ログ書き出しテスト\n",
    "\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('logs')\n",
    "\n",
    "def get_log_stream_token(log_group_name, log_stream_name):\n",
    "    # ログイベントがログストリームに存在する場合、書き込むを行うにはログストリームのトークンが必要なのでそれを取得する\n",
    "    response = client.describe_log_streams(\n",
    "        logGroupName=log_group_name,\n",
    "        logStreamNamePrefix=log_stream_name,\n",
    "    )\n",
    "    log_streams = response['logStreams']\n",
    "    log_stream = log_streams[0]\n",
    "    log_stream_token = log_stream['uploadSequenceToken']\n",
    "    return log_stream_token\n",
    "\n",
    "def put_custom_log_event(log_group_name, log_stream_name, log_stream_token):\n",
    "    # ログストリームのトークンを元にログイベントを書き込む\n",
    "    response = client.put_log_events(\n",
    "        logGroupName=log_group_name,\n",
    "        logStreamName=log_stream_name,\n",
    "        logEvents=[\n",
    "            {\n",
    "                'timestamp': int(time.time()) * 1000,\n",
    "                'message': 'testほげ'\n",
    "            },\n",
    "        ],\n",
    "        sequenceToken=log_stream_token\n",
    "      )\n",
    "\n",
    "def main():\n",
    "    log_group_name = '/aws/sagemaker/Endpoints/sagemakerinftest3'\n",
    "    log_stream_name = 'AllTraffic/i-03f1ee612f0e1aa0a'\n",
    "    log_stream_token= get_log_stream_token(log_group_name, log_stream_name)\n",
    "    put_custom_log_event(log_group_name, log_stream_name, log_stream_token)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c742735-65c1-4e90-afc2-4ef5daca239b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
